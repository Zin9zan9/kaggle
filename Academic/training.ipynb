{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('df_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog = ['First_choice', 'Single', 'Application_mode_1st_phase', 'Application_mode_2nd_phase', 'Application_mode_Over_23 years_old',\n",
    "        'Application_mode_Tech_Spec', 'Application_mode_Change', 'Quali_Secondary education', 'Quali_Basic education', \n",
    "        'Quali_Tech Spec course', 'Quali_Higher education', 'Quali_Other', 'Quali_12th year of schooling', 'Quali_Higher education',\n",
    "        'Quali_Professional higher technical course', 'M_Quali_Secondary education', 'M_Quali_Basic education_3rd', 'M_Quali_Basic education_1st',\n",
    "        'M_Quali_Basic education_2nd', 'M_Quali_Higher Education', 'M_Quali_Secondary education', 'M_Quali_Basic education_3rd',\n",
    "        'M_Quali_Basic education_1st', 'M_Quali_Basic education_2nd', 'M_Quali_Higher Education', 'F_Quali_Secondary education',\n",
    "        'F_Quali_Basic education_3rd', 'F_Quali_Basic education_1st', 'F_Quali_Basic education_2nd', 'F_Quali_Higher Education',\n",
    "        'Daytime/evening attendance', 'Previous qualification (grade)', 'Admission grade', 'Debtor', 'Tuition fees up to date',\n",
    "        'Gender', 'Scholarship holder', 'Age at enrollment', 'Curricular units 2nd sem (approved)', 'Curricular units 1st sem (approved)',\n",
    "        'Curricular units 2nd sem (grade)', 'Curricular units 1st sem (grade)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.33566021230443616\n",
      "            Iterations: 266\n",
      "            Function evaluations: 268\n",
      "            Gradient evaluations: 266\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.40899847348800433\n",
      "            Iterations: 264\n",
      "            Function evaluations: 267\n",
      "            Gradient evaluations: 264\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.25758092864441823\n",
      "            Iterations: 270\n",
      "            Function evaluations: 273\n",
      "            Gradient evaluations: 270\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train[exog]\n",
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "Y_train_g = df_train['Target_Graduate']\n",
    "Y_train_e = df_train['Target_Enrolled']\n",
    "Y_train_d = df_train['Target_Dropout']\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "\n",
    "Y_train_g = Y_train_g.astype(float)\n",
    "Y_train_e = Y_train_e.astype(float)\n",
    "Y_train_d = Y_train_d.astype(float)\n",
    "\n",
    "model_g = sm.Logit(Y_train_g, X_train, missing='drop').fit_regularized()\n",
    "model_e = sm.Logit(Y_train_e, X_train, missing='drop').fit_regularized()\n",
    "model_d = sm.Logit(Y_train_d, X_train, missing='drop').fit_regularized()\n",
    "\n",
    "train_pred = pd.DataFrame()\n",
    "train_pred['Graduate'] = model_g.predict(X_train)\n",
    "train_pred['Enrolled'] = model_e.predict(X_train)\n",
    "train_pred['Dropout'] = model_d.predict(X_train)\n",
    "\n",
    "# print(model.summary())\n",
    "# np.round(np.mean((model.predict(X_train)>0.5) == df['Target_Enrolled']),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(x):\n",
    "    if x['Graduate'] > x['Enrolled'] and x['Graduate'] > x['Dropout']:\n",
    "        return 'Graduate'\n",
    "    if x['Enrolled'] > x['Graduate'] and x['Enrolled'] > x['Dropout']:\n",
    "        return 'Enrolled'\n",
    "    if x['Dropout'] > x['Enrolled'] and x['Dropout'] > x['Graduate']:\n",
    "        return 'Dropout'\n",
    "    else:\n",
    "        return 'Graduate'\n",
    "    \n",
    "\n",
    "def target_to_num(x):\n",
    "    if x['Target'] == 'Graduate':\n",
    "        return 2\n",
    "    if x['Target'] == 'Dropout':\n",
    "        return 0\n",
    "    if x['Target'] == 'Enrolled':\n",
    "        return 1\n",
    "    \n",
    "def num_to_target(x):\n",
    "    if x['Target_num'] == 2:\n",
    "        return 'Graduate'\n",
    "    if x['Target_num'] == 0:\n",
    "        return 'Dropout'\n",
    "    if x['Target_num'] == 1:\n",
    "        return 'Enrolled'\n",
    "    \n",
    "\n",
    "def create_submission(y_pred, df_test, suffix=''):\n",
    "    data = {'id':df_test['id'],\n",
    "        'Target_num': y_pred.astype(int)}\n",
    "    submission = pd.DataFrame(data)\n",
    "    submission['Target'] = submission.apply(lambda x: num_to_target(x), axis=1)\n",
    "    submission.drop('Target_num', axis=1, inplace=True)\n",
    "    submission.to_csv(f'submission{suffix}.csv', index=False)\n",
    "\n",
    "\n",
    "df_train['Target_num'] = df_train.apply(lambda x: target_to_num(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7933\n",
      "   Graduate  Enrolled   Dropout    Target\n",
      "0  0.915459  0.115757  0.014734  Graduate\n",
      "1  0.014345  0.190726  0.848248   Dropout\n",
      "2  0.021586  0.077762  0.892209   Dropout\n",
      "3  0.964803  0.047911  0.013081  Graduate\n",
      "4  0.745402  0.229015  0.043680  Graduate\n"
     ]
    }
   ],
   "source": [
    "train_pred['Target'] = train_pred.apply(lambda x: classify(x), axis=1)\n",
    "print(np.round(np.mean(train_pred['Target'] == df_train['Target']),4))\n",
    "print(train_pred.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Graduate  Enrolled   Dropout    Target\n",
      "0  0.003010  0.011087  0.981896   Dropout\n",
      "1  0.753243  0.316973  0.032007  Graduate\n",
      "2  0.809270  0.125882  0.032804  Graduate\n",
      "3  0.710388  0.133592  0.053738  Graduate\n",
      "4  0.130881  0.451527  0.245270  Enrolled\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('df_clean_test.csv')\n",
    "X_test = df_test[exog]\n",
    "X_test = sm.add_constant(X_test)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "test_pred = pd.DataFrame()\n",
    "test_pred['Graduate'] = model_g.predict(X_test)\n",
    "test_pred['Enrolled'] = model_e.predict(X_test)\n",
    "test_pred['Dropout'] = model_d.predict(X_test)\n",
    "\n",
    "test_pred['Target'] = test_pred.apply(lambda x: classify(x), axis=1)\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = df_test['id']\n",
    "submission['Target'] = test_pred['Target']\n",
    "\n",
    "print(test_pred.head())\n",
    "submission.to_csv('submission_Logit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Score: 0.79543"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[exog]\n",
    "Y_train_num = df_train['Target_num']\n",
    "\n",
    "rf = RandomForestClassifier(max_features='auto', oob_score=True, random_state=0, n_jobs=-1)\n",
    "\n",
    "# param_grid = {\"criterion\":['gini', 'entropy', 'log_loss'], \"min_samples_leaf\" : [1, 2, 5], \"min_samples_split\" : [20], \"n_estimators\": [100]}\n",
    "\n",
    "# gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "\n",
    "# gs = gs.fit(X_train, Y_train_num)\n",
    "\n",
    "# print(gs.best_score_)\n",
    "# print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE MODEL: 0.8547977752578433\n",
      "0.81 accuracy with a standard deviation of 0.00\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=7, n_estimators=100, min_samples_split=20, min_samples_leaf=2)\n",
    "clf.fit(X_train, Y_train_num)\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "print(\"ACCURACY OF THE MODEL:\", metrics.accuracy_score(Y_train_num, y_pred))\n",
    "scores = cross_val_score(clf, X_train, Y_train_num, cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('df_clean_test.csv')\n",
    "X_test = df_test[exog]\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "create_submission(y_pred, df_test, '_rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Score: 0.81768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog = ['Previous qualification (grade)', 'Admission grade', 'Debtor', 'Tuition fees up to date',\n",
    "        'Gender', 'Scholarship holder', 'Age at enrollment', 'Curricular units 2nd sem (approved)', 'Curricular units 1st sem (approved)',\n",
    "        'Curricular units 2nd sem (grade)', 'Curricular units 1st sem (grade)']\n",
    "\n",
    "X_train_knn = X_train[exog]\n",
    "X_test_knn = X_test[exog]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_knn = scaler.fit(X_train_knn).transform(X_train_knn)\n",
    "X_test_knn = scaler.fit(X_test_knn).transform(X_test_knn)\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train_knn, Y_train_num, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7874595032397408\n",
      "0.79 accuracy with a standard deviation of 0.00\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(leaf_size=2, algorithm='auto', n_neighbors=5)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(clf.score(X_valid, Y_valid))\n",
    "y_pred = clf.predict(X_test_knn)\n",
    "\n",
    "scores = cross_val_score(clf, X_train, Y_train, cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "create_submission(y_pred, df_test, '_knn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog = ['First_choice', 'Single', 'Application_mode_1st_phase', 'Application_mode_2nd_phase', 'Application_mode_Over_23 years_old',\n",
    "        'Application_mode_Tech_Spec', 'Application_mode_Change', 'Quali_Secondary education', 'Quali_Basic education', \n",
    "        'Quali_Tech Spec course', 'Quali_Higher education', 'Quali_Other', 'Quali_12th year of schooling', 'Quali_Higher education',\n",
    "        'Quali_Professional higher technical course', 'M_Quali_Secondary education', 'M_Quali_Basic education_3rd', 'M_Quali_Basic education_1st',\n",
    "        'M_Quali_Basic education_2nd', 'M_Quali_Higher Education', 'M_Quali_Secondary education', 'M_Quali_Basic education_3rd',\n",
    "        'M_Quali_Basic education_1st', 'M_Quali_Basic education_2nd', 'M_Quali_Higher Education', 'F_Quali_Secondary education',\n",
    "        'F_Quali_Basic education_3rd', 'F_Quali_Basic education_1st', 'F_Quali_Basic education_2nd', 'F_Quali_Higher Education',\n",
    "        'Daytime/evening attendance', 'Previous qualification (grade)', 'Admission grade', 'Debtor', 'Tuition fees up to date',\n",
    "        'Gender', 'Scholarship holder', 'Age at enrollment', 'Curricular units 2nd sem (approved)', 'Curricular units 1st sem (approved)',\n",
    "        'Curricular units 2nd sem (grade)', 'Curricular units 1st sem (grade)']\n",
    "\n",
    "\n",
    "X_train = df_train[exog]\n",
    "Y_train_num = df_train['Target_num']\n",
    "\n",
    "X_train_std = X_train[exog]\n",
    "X_test_std = X_test[exog]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit(X_train_knn).transform(X_train_knn)\n",
    "X_test_std = scaler.fit(X_test_knn).transform(X_test_knn)\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train_knn, Y_train_num, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8116 accuracy with a standard deviation of 0.0065\n"
     ]
    }
   ],
   "source": [
    "model1 = XGBClassifier(n_estimators=100, learning_rate=0.01)\n",
    "model1.fit(X_train, Y_train,\n",
    "             eval_set=[(X_valid, Y_valid)], \n",
    "             verbose=False)\n",
    "\n",
    "predictions = model1.predict(X_valid)\n",
    "predictions\n",
    "\n",
    "scores = cross_val_score(model1, X_train, Y_train, cv=10)\n",
    "print(\"%0.4f accuracy with a standard deviation of %0.4f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(y_pred, df_test, suffix='_xgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog = ['First_choice', 'Single', 'Application_mode_1st_phase', 'Application_mode_2nd_phase', 'Application_mode_Over_23 years_old',\n",
    "        'Application_mode_Tech_Spec', 'Application_mode_Change', 'Quali_Secondary education', 'Quali_Basic education', \n",
    "        'Quali_Tech Spec course', 'Quali_Higher education', 'Quali_Other', 'Quali_12th year of schooling', 'Quali_Higher education',\n",
    "        'Quali_Professional higher technical course', 'M_Quali_Secondary education', 'M_Quali_Basic education_3rd', 'M_Quali_Basic education_1st',\n",
    "        'M_Quali_Basic education_2nd', 'M_Quali_Higher Education', 'M_Quali_Secondary education', 'M_Quali_Basic education_3rd',\n",
    "        'M_Quali_Basic education_1st', 'M_Quali_Basic education_2nd', 'M_Quali_Higher Education', 'F_Quali_Secondary education',\n",
    "        'F_Quali_Basic education_3rd', 'F_Quali_Basic education_1st', 'F_Quali_Basic education_2nd', 'F_Quali_Higher Education',\n",
    "        'Daytime/evening attendance', 'Previous qualification (grade)', 'Admission grade', 'Debtor', 'Tuition fees up to date',\n",
    "        'Gender', 'Scholarship holder', 'Age at enrollment', 'Curricular units 2nd sem (approved)', 'Curricular units 1st sem (approved)',\n",
    "        'Curricular units 2nd sem (grade)', 'Curricular units 1st sem (grade)']\n",
    "\n",
    "df_train = pd.read_csv('df_clean.csv')\n",
    "df_train['Target_num'] = df_train.apply(lambda x: target_to_num(x), axis=1)\n",
    "\n",
    "X_train = df_train[exog]\n",
    "Y_train_num = df_train['Target_num']\n",
    "\n",
    "X_train_std = X_train[exog]\n",
    "X_test_std = X_test[exog]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit(X_train_knn).transform(X_train_knn)\n",
    "X_test_std = scaler.fit(X_test_knn).transform(X_test_knn)\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train_knn, Y_train_num, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.63479990\n",
      "Iteration 2, loss = 0.51736210\n",
      "Iteration 3, loss = 0.50480733\n",
      "Iteration 4, loss = 0.49902223\n",
      "Iteration 5, loss = 0.49612705\n",
      "Iteration 6, loss = 0.49440313\n",
      "Iteration 7, loss = 0.49333277\n",
      "Iteration 8, loss = 0.49274508\n",
      "Iteration 9, loss = 0.49202531\n",
      "Iteration 10, loss = 0.49184533\n",
      "Iteration 11, loss = 0.49124431\n",
      "Iteration 12, loss = 0.49101416\n",
      "Iteration 13, loss = 0.49064927\n",
      "Iteration 14, loss = 0.49040772\n",
      "Iteration 15, loss = 0.49016217\n",
      "Iteration 16, loss = 0.48974863\n",
      "Iteration 17, loss = 0.48966954\n",
      "Iteration 18, loss = 0.48933073\n",
      "Iteration 19, loss = 0.48914231\n",
      "Iteration 20, loss = 0.48863994\n",
      "Iteration 21, loss = 0.48867865\n",
      "Iteration 22, loss = 0.48823928\n",
      "Iteration 23, loss = 0.48854290\n",
      "Iteration 24, loss = 0.48800748\n",
      "Iteration 25, loss = 0.48793595\n",
      "Iteration 26, loss = 0.48774693\n",
      "Iteration 27, loss = 0.48742725\n",
      "Iteration 28, loss = 0.48744166\n",
      "Iteration 29, loss = 0.48730890\n",
      "Iteration 30, loss = 0.48708470\n",
      "Iteration 31, loss = 0.48696752\n",
      "Iteration 32, loss = 0.48687740\n",
      "Iteration 33, loss = 0.48691570\n",
      "Iteration 34, loss = 0.48668220\n",
      "Iteration 35, loss = 0.48639803\n",
      "Iteration 36, loss = 0.48637787\n",
      "Iteration 37, loss = 0.48614063\n",
      "Iteration 38, loss = 0.48599457\n",
      "Iteration 39, loss = 0.48612999\n",
      "Iteration 40, loss = 0.48595168\n",
      "Iteration 41, loss = 0.48578510\n",
      "Iteration 42, loss = 0.48571922\n",
      "Iteration 43, loss = 0.48555008\n",
      "Iteration 44, loss = 0.48559288\n",
      "Iteration 45, loss = 0.48555591\n",
      "Iteration 46, loss = 0.48544710\n",
      "Iteration 47, loss = 0.48531224\n",
      "Iteration 48, loss = 0.48529651\n",
      "Iteration 49, loss = 0.48505605\n",
      "Iteration 50, loss = 0.48487365\n",
      "Iteration 51, loss = 0.48515220\n",
      "Iteration 52, loss = 0.48475998\n",
      "Iteration 53, loss = 0.48493183\n",
      "Iteration 54, loss = 0.48470473\n",
      "Iteration 55, loss = 0.48460699\n",
      "Iteration 56, loss = 0.48471398\n",
      "Iteration 57, loss = 0.48438916\n",
      "Iteration 58, loss = 0.48449232\n",
      "Iteration 59, loss = 0.48428232\n",
      "Iteration 60, loss = 0.48439213\n",
      "Iteration 61, loss = 0.48420712\n",
      "Iteration 62, loss = 0.48418377\n",
      "Iteration 63, loss = 0.48443853\n",
      "Iteration 64, loss = 0.48409427\n",
      "Iteration 65, loss = 0.48399506\n",
      "Iteration 66, loss = 0.48397337\n",
      "Iteration 67, loss = 0.48420090\n",
      "Iteration 68, loss = 0.48394061\n",
      "Iteration 69, loss = 0.48399174\n",
      "Iteration 70, loss = 0.48388491\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8132635842051974"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=1, hidden_layer_sizes=[16, 16], max_iter=10000, verbose=True).fit(X_train, Y_train)\n",
    "\n",
    "clf.score(X_train, Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
